{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting information from a shared chatGPT chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For background see this discussion comment: [Accessing OpenAI Chat Data and Shared Conversations\n",
    "](https://github.com/thorwhalen/oa/discussions/11#discussioncomment-11852719)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['basename', 'future', 'isSpaMode', 'state']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from oa.chats import url_to_html, parse_shared_chatGPT_chat\n",
    "\n",
    "url = 'https://chatgpt.com/share/6788d539-0f2c-8013-9535-889bf344d7d5'\n",
    "chat_html = url_to_html(url)\n",
    "chat_json_dict = parse_shared_chatGPT_chat(chat_html)\n",
    "list(chat_json_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping the parsing (and maintaining the parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a look at the `parse_shared_chatGPT_chat` you'll notice it's parametrized by several arguments you didn't have to specify.\n",
    "\n",
    "```python\n",
    "def parse_shared_chatGPT_chat(\n",
    "    html: str,\n",
    "    is_target_string: Union[str, Callable] = 'data.*mapping.*message',\n",
    "    *,\n",
    "    variable_name: str = 'window.__remixContext',\n",
    "    json_pattern: str = '(\\\\{.*?\\\\});') -> dict\n",
    ") -> dict:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(html: str,\n",
      " is_target_string: Union[str,\n",
      " Callable] = 'data.*mapping.*message',\n",
      " *,\n",
      " variable_name: str = 'window.__remixContext',\n",
      " json_pattern: str = '(\\\\{.*?\\\\});') -> dict\n"
     ]
    }
   ],
   "source": [
    "from i2 import Sig\n",
    "\n",
    "print(',\\n'.join(str(Sig(parse_shared_chatGPT_chat)).split(',')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did this so that we can easily maintain the parser's definition. \n",
    "\n",
    "At the time of writing this, we've noticed that the json we want is assigned to a \n",
    "variable named `window.__remixContext` and has fields `data`, `mapping`, and `message` in that order. \n",
    "\n",
    "But to be able to get that in the first place, we used `parse_shared_chatGPT_chat` with different parameters. \n",
    "\n",
    "We tried it with a chat we knew the contents of, and asked `parse_shared_chatGPT_chat` to find the json \n",
    "based on a substring we knew should be in there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['basename', 'future', 'isSpaMode', 'state']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from oa.chats import url_to_html, parse_shared_chatGPT_chat\n",
    "\n",
    "url = 'https://chatgpt.com/share/6788d539-0f2c-8013-9535-889bf344d7d5'\n",
    "string_contained_in_conversation = 'apple, river, galaxy, chair, melody, shadow, cloud, puzzle, flame, whisper'\n",
    "chat_html = url_to_html(url)\n",
    "chat_json_dict = parse_shared_chatGPT_chat(chat_html, is_target_string=string_contained_in_conversation)\n",
    "list(chat_json_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a truncated version of this dict, to make sure it's not too big to study..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['basename', 'future', 'isSpaMode', 'state']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lkj import truncate_dict_values\n",
    "from pprint import pprint\n",
    "from pyperclip import copy\n",
    "\n",
    "\n",
    "t = truncate_dict_values(chat_json_dict)\n",
    "list(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330325"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save this truncated dict to a file\n",
    "import tempfile\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "tmp_filepath = tempfile.mktemp()\n",
    "Path\n",
    "\n",
    "\n",
    "len(json.dumps(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing out the json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is probably the most fragile part of the process. \n",
    "It's the part that broke previous tools I found to solve my problem.\n",
    "\n",
    "The approach I'm taking here is to identify a part of the conversation that I know should be in the conversation, and using that to find what I'm looking for. \n",
    "\n",
    "So what I did here is copy the html of a conversation and used chatGPT (o1) to help me out. \n",
    "[Here's the conversation](https://chatgpt.com/share/6788d964-9e60-8013-a2b3-e191d567c8ad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['basename', 'future', 'isSpaMode', 'state']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bootstrapping (when you don't know the structure, but you do know of a string that is contained in the conversation)\n",
    "\n",
    "from oa.chats import parse_shared_chatGPT_chat, url_to_html\n",
    "\n",
    "url = 'https://chatgpt.com/share/6788d539-0f2c-8013-9535-889bf344d7d5'\n",
    "string_contained_in_conversation = 'apple, river, galaxy, chair, melody, shadow, cloud, puzzle, flame, whisper'\n",
    "\n",
    "chat_html = url_to_html(url)\n",
    "chat_json_dict = parse_shared_chatGPT_chat(chat_html, is_target_string=string_contained_in_conversation)\n",
    "list(chat_json_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a truncated version of the chat_json_dict (too big to study!)\n",
    "from lkj import truncate_dict_values\n",
    "import json \n",
    "\n",
    "truncated_json_dict = truncate_dict_values(chat_json_dict, max_list_size=1, max_string_size=90)\n",
    "truncated_json_dict_string = json.dumps(truncated_json_dict, indent=2)\n",
    "assert string_contained_in_conversation in truncated_json_dict_string, (\n",
    "    \"The string_contained_in_conversation is not in the truncated_json_dict_string. Increase the max_* parameters.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584063 characters written to /var/folders/mc/c070wfh51kxd9lft8dl74q1r0000gn/T/tmph5v0uvws.json\n"
     ]
    }
   ],
   "source": [
    "# Save to a file to go study it...\n",
    "\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "tmp_filepath = tempfile.mktemp() + '.json'\n",
    "Path(tmp_filepath).write_text(truncated_json_dict_string)\n",
    "print(f\"{len(truncated_json_dict_string)} characters written to {tmp_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing out the conversation part of the json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('state',\n",
       " 'loaderData',\n",
       " 'routes/share.$shareId.($action)',\n",
       " 'serverResponse',\n",
       " 'data',\n",
       " 'mapping',\n",
       " '38ee4a3f-8487-4b35-9f92-ddee57c25d0a',\n",
       " 'message',\n",
       " 'content',\n",
       " 'parts')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from oa.chats import find_all_matching_paths_in_list_values\n",
    "from dol import path_get\n",
    "\n",
    "paths = find_all_matching_paths_in_list_values(truncated_json_dict, target_value=string_contained_in_conversation)\n",
    "path = next(paths)\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we know the path to where our target string can be found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello World!  \\napple, river, galaxy, chair, melody, shadow, cloud, puzzle, flame, whisper.']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_get(truncated_json_dict, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look around it to get a better sense of the relevant json structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content_type': 'text',\n",
       " 'parts': ['Hello World!  \\napple, river, galaxy, chair, melody, shadow, cloud, puzzle, flame, whisper.']}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_get(truncated_json_dict, path[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '38ee4a3f-8487-4b35-9f92-ddee57c25d0a',\n",
       " 'author': {'role': 'assistant', 'metadata': {}},\n",
       " 'create_time': 1737020652.436654,\n",
       " 'content': {'content_type': 'text',\n",
       "  'parts': ['Hello World!  \\napple, river, galaxy, chair, melody, shadow, cloud, puzzle, flame, whisper.']},\n",
       " 'status': 'finished_successfully',\n",
       " 'end_turn': True,\n",
       " 'weight': 1,\n",
       " 'metadata': {'finish_details': {'type': 'stop', 'stop_tokens': [200002]},\n",
       "  'is_complete': True,\n",
       "  'citations': [],\n",
       "  'content_references': [],\n",
       "  'message_type': None,\n",
       "  'model_slug': 'gpt-4o',\n",
       "  'default_model_slug': 'gpt-4o',\n",
       "  'parent_id': '94469d89-ff37-48c1-bdab-44b27299d79b',\n",
       "  'request_id': '902d2a5a0ed1e15c-MRS',\n",
       "  'timestamp_': 'absolute',\n",
       "  'shared_conversation_id': '6788d539-0f2c-8013-9535-889bf344d7d5'},\n",
       " 'recipient': 'all'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_get(truncated_json_dict, path[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('state', 'loaderData', 'routes/share.$shareId.($action)', 'serverResponse', 'data', 'mapping')\n"
     ]
    }
   ],
   "source": [
    "print(path[:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A wild guess.\n",
    "`('state', 'loaderData', 'routes/share.$shareId.($action)', 'serverResponse', 'data', 'mapping')` is where the \"turns\" of the conversation are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adff303b-75cc-493c-b757-605adadb8e56',\n",
       " '1473f2d9-ba09-4cd7-90c4-1452898676de',\n",
       " '40c5ed53-2b82-4e38-a4ec-dabf8f589553',\n",
       " '3b469b70-b069-4640-98af-5417491bb626',\n",
       " '94469d89-ff37-48c1-bdab-44b27299d79b',\n",
       " '38ee4a3f-8487-4b35-9f92-ddee57c25d0a',\n",
       " '01808c08-dc33-4932-bc12-64bd7e936760',\n",
       " 'be4486db-894f-4e6f-bd0a-22d9d2facf69']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turns_path = ('state', 'loaderData', 'routes/share.$shareId.($action)', 'serverResponse', 'data', 'mapping')\n",
    "turns_data = path_get(truncated_json_dict, turns_path)\n",
    "list(turns_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title',\n",
       " 'create_time',\n",
       " 'update_time',\n",
       " 'mapping',\n",
       " 'moderation_results',\n",
       " 'current_node',\n",
       " 'conversation_id',\n",
       " 'is_archived',\n",
       " 'safe_urls',\n",
       " 'default_model_slug',\n",
       " 'disabled_tool_ids',\n",
       " 'is_public',\n",
       " 'linear_conversation',\n",
       " 'has_user_editable_context',\n",
       " 'continue_conversation_url',\n",
       " 'moderation_state',\n",
       " 'is_indexable',\n",
       " 'is_better_metatags_enabled']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_data_path = turns_path[:-1]\n",
    "list(path_get(truncated_json_dict, chat_data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Test Chat 1',\n",
       " 'create_time': 1737020729.060687,\n",
       " 'update_time': 1737020733.031014,\n",
       " 'moderation_results': [],\n",
       " 'current_node': 'be4486db-894f-4e6f-bd0a-22d9d2facf69',\n",
       " 'conversation_id': '6788d539-0f2c-8013-9535-889bf344d7d5',\n",
       " 'is_archived': False,\n",
       " 'safe_urls': [],\n",
       " 'default_model_slug': 'gpt-4o',\n",
       " 'disabled_tool_ids': [],\n",
       " 'is_public': True,\n",
       " 'linear_conversation': [{'id': 'adff303b-75cc-493c-b757-605adadb8e56',\n",
       "   'children': ['1473f2d9-ba09-4cd7-90c4-1452898676de']}],\n",
       " 'has_user_editable_context': False,\n",
       " 'continue_conversation_url': 'https://chatgpt.com/share/6788d539-0f2c-8013-9535-889bf344d7d5/continue',\n",
       " 'moderation_state': {'has_been_moderated': False,\n",
       "  'has_been_blocked': False,\n",
       "  'has_been_accepted': False,\n",
       "  'has_been_auto_blocked': False,\n",
       "  'has_been_auto_moderated': False},\n",
       " 'is_indexable': False,\n",
       " 'is_better_metatags_enabled': True}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = path_get(truncated_json_dict, chat_data_path)\n",
    "metadata = {k: v for k, v in metadata.items() if k != 'mapping'}\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some documentation for this part of the chat json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function oa.tools.prompt_function.<locals>.ask_oa(example_json, *, context=' just a general context')>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from oa import prompt_function\n",
    "\n",
    "\n",
    "mk_json_field_documentation = prompt_function(\"\"\"\n",
    "You are a technical writer specialized in documenting JSON fields. \n",
    "Below is a JSON object. I'd like you to document each field in a markdown table.\n",
    "The table should contain the name, description, and example value of each field.\n",
    "                                              \n",
    "The context is:\n",
    "{context: just a general context}\n",
    "                                              \n",
    "Here's an example json object:\n",
    "\n",
    "{example_json}\n",
    "\"\"\")\n",
    "\n",
    "mk_json_field_documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the documentation for the provided JSON object, structured in a markdown table format:\n",
      "\n",
      "| Field Name                                         | Description                                                                                     | Example Value                                                                         |\n",
      "|---------------------------------------------------|-------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------|\n",
      "| `<Conversation ID>`                               | Unique identifier for each turn in the conversation.                                          | `adff303b-75cc-493c-b757-605adadb8e56`                                             |\n",
      "| `id`                                              | The unique identifier for the specific message/turn.                                         | `adff303b-75cc-493c-b757-605adadb8e56`                                             |\n",
      "| `children`                                        | An array of IDs representing subsequent messages/turns that are children of this turn.       | `[\"1473f2d9-ba09-4cd7-90c4-1452898676de\"]`                                         |\n",
      "| `message`                                         | Contains details about the message that was sent.                                            | `{...}` (Object with further nested fields)                                         |\n",
      "| `author`                                          | Specifies the author of the message, including their role and metadata.                      | `{ \"role\": \"system\", \"metadata\": {} }`                                            |\n",
      "| `content`                                         | Contains the content of the message, specifying the type and actual message parts.           | `{ \"content_type\": \"text\", \"parts\": [\"\"] }`                                       |\n",
      "| `status`                                         | The status of the message indicating the completion state.                                    | `finished_successfully`                                                              |\n",
      "| `end_turn`                                       | Boolean indicating whether this message marks the end of a conversation turn.                 | `true`                                                                               |\n",
      "| `weight`                                         | Numerical value representing the significance or order of the turn in the conversation.      | `0`                                                                                  |\n",
      "| `metadata`                                       | Contains additional information about the message, such as visibility and identifiers.         | `{ \"is_visually_hidden_from_conversation\": true, \"shared_conversation_id\": \"6788d539-0f2c-8013-9535-889bf344d7d5\" }` |\n",
      "| `recipient`                                       | The intended recipient(s) of the message, indicating audience scope.                         | `all`                                                                                |\n",
      "| `parent`                                          | ID of the parent turn/message to which this turn is a response.                              | `adff303b-75cc-493c-b757-605adadb8e56`                                             |\n",
      "| `create_time`                                     | Timestamp indicating the creation time of the message, in Unix time format.                   | `1737020650.866734`                                                                  |\n",
      "| `is_user_system_message`                          | Indicates if the message is a system message from the user.                                  | `true`                                                                               |\n",
      "| `is_redacted`                                     | Indicates if the message has been redacted for privacy or security reasons.                   | `true`                                                                               |\n",
      "| `finish_details`                                 | Provides details on how the message was concluded, including stop tokens.                     | `{ \"type\": \"stop\", \"stop_tokens\": [200002] }`                                     |\n",
      "| `model_slug`                                      | Identifies the model used for generating the message response.                                | `gpt-4o`                                                                             |\n",
      "| `default_model_slug`                              | The default model slug used for the current conversation context.                             | `gpt-4o`                                                                             |\n",
      "| `timestamp_`                                      | A string indicating the timestamp's nature (e.g., 'absolute').                               | `absolute`                                                                           |\n",
      "| `content_type`                                    | The type of content within the message, such as `text`, `model_editable_context`, etc.       | `text`                                                                               |\n",
      "| `parts`                                           | An array containing the actual parts of the message content.                                   | `[\"Hello World! \\napple, river, galaxy, chair, melody, shadow, cloud, puzzle, flame, whisper.\"]` |\n",
      "\n",
      "This table documents the fields found within the JSON object representing a shared conversation of turns in a chat platform. Each field is described to inform developers or users of its structure and purpose, along with example values for clarity.\n"
     ]
    }
   ],
   "source": [
    "metadata_field_docs = mk_json_field_documentation(\n",
    "    json.dumps(turns_data, indent=2), \n",
    "    context=\"the conversation 'turns' of the json object holding a shared chatGPT conversation\"\n",
    ")\n",
    "print(metadata_field_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the documentation for each field in the provided JSON object, formatted as a markdown table:\n",
      "\n",
      "| Field Name                                | Description                                                                                          | Example Value                                                      |\n",
      "|-------------------------------------------|------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------|\n",
      "| `title`                                   | The title of the shared chat GPT conversation.                                                      | \"Test Chat 1\"                                                    |\n",
      "| `create_time`                             | The timestamp when the conversation was created, represented in seconds since the Unix epoch.      | 1737020729.060687                                                |\n",
      "| `update_time`                             | The timestamp when the conversation was last updated, represented in seconds since the Unix epoch. | 1737020733.031014                                                |\n",
      "| `moderation_results`                      | An array containing results of moderation checks, if any.                                          | []                                                               |\n",
      "| `current_node`                            | The unique identifier of the current node in the conversation tree.                                 | \"be4486db-894f-4e6f-bd0a-22d9d2facf69\"                        |\n",
      "| `conversation_id`                         | A unique identifier for the conversation.                                                           | \"6788d539-0f2c-8013-9535-889bf344d7d5\"                         |\n",
      "| `is_archived`                             | A boolean value indicating whether the conversation is archived.                                     | false                                                             |\n",
      "| `safe_urls`                               | An array of URLs that have been deemed safe in the conversation.                                    | []                                                               |\n",
      "| `default_model_slug`                      | The slug representing the default model used for the conversation.                                  | \"gpt-4o\"                                                         |\n",
      "| `disabled_tool_ids`                       | An array of identifiers for tools that have been disabled for this conversation.                    | []                                                               |\n",
      "| `is_public`                               | A boolean value indicating whether the conversation is accessible to the public.                    | true                                                              |\n",
      "| `linear_conversation`                     | An array representing the conversation in a linear format with node identifiers.                    | [{\"id\": \"adff303b-75cc-493c-b757-605adadb8e56\", \"children\": [\"1473f2d9-ba09-4cd7-90c4-1452898676de\"]}] |\n",
      "| `has_user_editable_context`              | A boolean value indicating if the user can edit context for the conversation.                       | false                                                             |\n",
      "| `continue_conversation_url`               | A URL that allows the user to continue the conversation.                                            | \"https://chatgpt.com/share/6788d539-0f2c-8013-9535-889bf344d7d5/continue\" |\n",
      "| `moderation_state`                        | An object containing the state of moderation checks applied to the conversation.                     | {\"has_been_moderated\": false, \"has_been_blocked\": false, \"has_been_accepted\": false, \"has_been_auto_blocked\": false, \"has_been_auto_moderated\": false} |\n",
      "| `is_indexable`                           | A boolean value indicating whether the conversation can be indexed for search purposes.             | false                                                             |\n",
      "| `is_better_metatags_enabled`             | A boolean value indicating whether enhanced metatags are enabled for this conversation.             | true                                                              |\n",
      "\n",
      "This table provides a concise overview of each field, its purpose, and an illustrative example.\n"
     ]
    }
   ],
   "source": [
    "metadata_field_docs = mk_json_field_documentation(\n",
    "    json.dumps(metadata, indent=2), \n",
    "    context=\"metadata of a shared chatGPT conversation\"\n",
    ")\n",
    "print(metadata_field_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from typing import Callable, Optional\n",
    "\n",
    "def raise_run_time_error(msg: str):\n",
    "    raise RuntimeError(msg)\n",
    "\n",
    "def extract_json_dict(\n",
    "    string: str,\n",
    "    object_filter: Callable,\n",
    "    *,\n",
    "    decoder: json.JSONDecoder = json.JSONDecoder(),\n",
    "    not_found_callback: Optional[\n",
    "        Callable\n",
    "    ] = lambda string, object_filter: raise_run_time_error(\n",
    "        \"Object not found in string\"\n",
    "    ),\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Searches `string` from the beginning, attempting to decode consecutive\n",
    "    JSON objects using `decoder.raw_decode`. When an object satisfies\n",
    "    `object_filter`, returns it as a Python dictionary.\n",
    "    \"\"\"\n",
    "    pos = 0\n",
    "    while pos < len(string):\n",
    "        try:\n",
    "            obj, pos = decoder.raw_decode(string, pos)\n",
    "            if object_filter(obj):\n",
    "                return obj\n",
    "        except json.JSONDecodeError:\n",
    "            pos += 1\n",
    "    return not_found_callback(string, object_filter)\n",
    "\n",
    "def parse_shared_chatGPT_chat(\n",
    "    html: str, \n",
    "    string_contained_in_conversation: str\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Locates the big JSON structure assigned to window.__remixContext, \n",
    "    checks that the conversation portion includes `string_contained_in_conversation`,\n",
    "    and returns the JSON as a dict.\n",
    "    \"\"\"\n",
    "    # Regex pattern to capture the object assigned to window.__remixContext = {...};\n",
    "    pattern = r\"window\\.__remixContext\\s*=\\s*(\\{.*?\\});\"\n",
    "    match = re.search(pattern, html, flags=re.DOTALL)\n",
    "    if not match:\n",
    "        raise RuntimeError(\"Could not locate the JSON assigned to window.__remixContext\")\n",
    "\n",
    "    # Extract the raw JSON text (removing the trailing semicolon if needed)\n",
    "    raw_json_text = match.group(1).strip()\n",
    "\n",
    "    # We'll define a filter that checks if the conversation data includes the target string.\n",
    "    # Because the JSON is quite large, we can simply check if the substring is present in the raw text:\n",
    "    # but if we want to be more precise, we can parse first and only return if there's conversation data.\n",
    "    def conversation_filter(obj):\n",
    "        # Convert to string once more, or deeply check \"routes/share.$shareId.($action)\" for the substring.\n",
    "        # For simplicity, do a textual check on the entire string representation. \n",
    "        # If needed, we can refine to parse a specific location in obj.\n",
    "        return string_contained_in_conversation in json.dumps(obj, ensure_ascii=False)\n",
    "\n",
    "    # Now parse the JSON, returning only if the filter passes\n",
    "    extracted_dict = extract_json_dict(\n",
    "        raw_json_text,\n",
    "        object_filter=conversation_filter,\n",
    "    )\n",
    "\n",
    "    return extracted_dict\n",
    "\n",
    "\n",
    "t = parse_shared_chatGPT_chat(html, existing_substring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['basename', 'future', 'isSpaMode', 'state']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
