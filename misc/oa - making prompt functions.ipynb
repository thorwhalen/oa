{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demos how to make prompt functions -- that is, python functions that \n",
    "are defined by prompt templates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-defined prompt functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a few pre-defined prompt functions that come with the `oa` package. \n",
    "We'll start looking at those, and then see how to make them..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prompt_template_improver',\n",
       " 'user_story_to_code_for_dag',\n",
       " 'prompt_template_starter',\n",
       " 'make_synopsis',\n",
       " 'description_to_software_specs',\n",
       " 'define_jargon',\n",
       " 'simple_tests_for_code',\n",
       " 'suggest_names',\n",
       " 'specs_to_code_for_dag']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from oa import ask\n",
    "from inspect import signature\n",
    "\n",
    "print_signature = lambda func: print(signature(func))\n",
    "\n",
    "list(ask.ai)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prompt_template_starter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of particular interest to use here is an AI-enabled function that will help us make AI-enabled functions...\n",
    "\n",
    "It has two inputs:\n",
    "- a `task`, which is a specification of what we want a prompt template for\n",
    "- `inputs`, which is a specification of what \"variables\" this prompt template should have, that is, what kinds of inputs we're going to ask the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(task, *, inputs=' ')\n"
     ]
    }
   ],
   "source": [
    "print_signature(ask.ai.prompt_template_starter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we go through a bit of experimentation, trying out different ways of expressing what we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a language teacher. Teach me how to say {this} in the new language.\n"
     ]
    }
   ],
   "source": [
    "template = ask.ai.prompt_template_starter(\n",
    "    task=\"\"\"\n",
    "    Help me learn a new language\n",
    "    \"\"\",\n",
    "    inputs = \"\"\n",
    ")\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a language learning expert. Translate the following sentences into {language} using the vocabulary words: {vocabulary_words}. Translate {number_of_sentences} sentences.\n"
     ]
    }
   ],
   "source": [
    "template = ask.ai.prompt_template_starter(\n",
    "    task=\"\"\"\n",
    "    Help me learn new vocabulary words of a language that I'm learning\n",
    "    by giving me some sentences that I should translate into the language I am learning.\n",
    "    \"\"\",\n",
    "    inputs = \"language, vocabulary_words, number_of_sentences\"\n",
    ")\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we settle on some template, possibly editing it a bit, and make a prompt function out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(vocabulary_words, *, language='Japanese', number_of_sentences='3')\n"
     ]
    }
   ],
   "source": [
    "from oa import prompt_function\n",
    "\n",
    "template = \"\"\"\n",
    "You are a language learning expert. Translate the following sentences into {language:Japanese} \n",
    "using the vocabulary words: {vocabulary_words}. \n",
    "Give me a list of {number_of_sentences:3} to translate followed with an ANSWERS section where \n",
    "you'll list the actual translations.\n",
    "\"\"\"\n",
    "practice_vocab = prompt_function(template)\n",
    "print_signature(practice_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this function out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Hello, please give me some tasty sushi.\n",
      "2. Thank you for the tasty sushi.\n",
      "3. Hello, may I please have some more tasty sushi?\n",
      "\n",
      "ANSWERS:\n",
      "1. こんにちは、美味しい寿司をください。\n",
      "2. 美味しい寿司をありがとうございます。\n",
      "3. こんにちは、美味しい寿司をもう少しいただけますか。\n"
     ]
    }
   ],
   "source": [
    "print(practice_vocab(\"tasty, sushi, hello, please, thank you\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what the underlying template looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "```\n",
      "You are an expert prompt engineer.\n",
      "I will give you a task below and would like you to write a “prompt template” to perform this task.\n",
      "This task will be parametrized by some inputs, which should appear in the prompt template as placeholders, marked by braces {like} {this} (here, both “like” and “this” are names of inputs that would parametrize the prompt template). \n",
      "I might give you an explicit list of inputs, which will be a comma or space separated list of strings (to be more precise, python identifier strings (so only alphanumerics and underscores).\n",
      "If I do give you this list of inputs (names), you should use them (all) in the prompt template, using the {braces} to show where these should be injected when making a prompt (I have code for that). \n",
      "You should use them all.\n",
      "If I don’t give you this list of inputs (that is, my list of inputs is empty), you should come up with your own. Remember; I’m going to use this template to make a form to get inputs from the user, so I need this form to contain input fields, so I need my prompt template to have named placeholders to inject the inputs in and make a prompt. \n",
      "Also, your output should ONLY be the prompt template, with no explanation, before or after\n",
      "\n",
      "Here’s two examples: \n",
      "\n",
      "###\n",
      "\n",
      "My input:\n",
      "Task: Generate jokes\n",
      "Inputs:\n",
      "\n",
      "Your output:\n",
      "You are an expert comedy writer. Write me a joke about {this}.\n",
      "\n",
      "###\n",
      "\n",
      "My input:\n",
      "Task: Generate jokes\n",
      "Inputs: subject_of_joke, approx_number_of_words\n",
      "\n",
      "Your output:\n",
      "You are an expert comedy writer. Write me a joke about {subject_of_joke} with about {approx_number_of_words}\n",
      "```\n",
      "\n",
      "###\n",
      "\n",
      "Here’s my first actual input:\n",
      "Task: {task}\n",
      "Inputs: {inputs: }\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ask.ai.prompt_template_starter.template_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prompt_template_improver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a template that works. How can we improve it?\n",
    "\n",
    "Let's use another (prompt-based) function for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a language learning expert. Translate the following sentences into {language:Japanese} \n",
    "using the vocabulary words: {vocabulary_words}. \n",
    "Give me a list of {number_of_sentences:3} to translate followed with an ANSWERS section where \n",
    "you'll list the actual translations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(prompt_template, *, specific_goals=' ', number_of_alternatives='3', include_additional_explanations='false', prompt_engineering_tips='false')\n"
     ]
    }
   ],
   "source": [
    "print_signature(ask.ai.prompt_template_improver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Prompt Alternatives:**\n",
      "1. You are a language learning expert. Translate the following sentences into {language:Japanese} using the vocabulary words: {vocabulary_words}. Give me a list of {number_of_sentences:3} to translate followed with an ANSWERS section where you'll list the actual translations.\n",
      "  \n",
      "2. As a language learning expert, I need you to translate the following sentences into {language:Japanese} with the provided vocabulary words: {vocabulary_words}. Provide a list of {number_of_sentences:3} to translate, followed by an ANSWERS section where the actual translations will be listed.\n",
      "\n",
      "3. Calling all language learning experts! Your task is to translate the following sentences into {language:Japanese} using the vocabulary words: {vocabulary_words}. I need a list of {number_of_sentences:3} translations, followed by an ANSWERS section detailing the actual translations.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alternative_template_1 = ask.ai.prompt_template_improver(template)\n",
    "print(alternative_template_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative 1:\n",
      "You are a language learning expert. Translate the following sentences into {language:Japanese} \n",
      "using the vocabulary words: {vocabulary_words}. \n",
      "Give me a list of {number_of_sentences:3} to translate followed with an ANSWERS section where \n",
      "you'll list the actual translations.\n",
      "\n",
      "Alternative 2:\n",
      "As a language learning expert, translate the sentences below into {language:Japanese} \n",
      "with the given vocabulary words: {vocabulary_words}. \n",
      "Provide {number_of_sentences:3} translations and list them in the ANSWERS section.\n",
      "\n",
      "ADDITIONAL EXPLANATIONS:\n",
      "In these alternatives, the focus is on the vocabulary words provided, ensuring that the translations stick closely to them. By structuring the prompt in a specific format, it can help guide the expert towards using the vocabulary effectively in the translations.\n",
      "\n",
      "PROMPT ENGINEERING TIPS:\n",
      "1. Encourage the expert to utilize the vocabulary words creatively by providing a variety of sentence structures to translate.\n",
      "2. Remind the expert to pay attention to nuances and context when translating to ensure accuracy while staying focused on the vocabulary words.\n"
     ]
    }
   ],
   "source": [
    "alternative_template_2 = ask.ai.prompt_template_improver(\n",
    "    template,\n",
    "    specific_goals='To stay more focused on the vocabulary words, departing from them as little as possible', \n",
    "    number_of_alternatives=2, \n",
    "    include_additional_explanations=True, \n",
    "    prompt_engineering_tips=True\n",
    ")\n",
    "print(alternative_template_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## changing the chat model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not good enough?\n",
    "\n",
    "Perhaps the prompt is good enough, but not the ai?\n",
    "\n",
    "Let's try to change the model we're using!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['whisper-1',\n",
       " 'davinci-002',\n",
       " 'dall-e-2',\n",
       " 'tts-1-hd-1106',\n",
       " 'tts-1-hd',\n",
       " 'gpt-3.5-turbo',\n",
       " 'gpt-3.5-turbo-0125',\n",
       " 'gpt-3.5-turbo-instruct-0914',\n",
       " 'gpt-3.5-turbo-16k-0613',\n",
       " 'gpt-3.5-turbo-16k',\n",
       " 'gpt-3.5-turbo-instruct',\n",
       " 'gpt-3.5-turbo-0301',\n",
       " 'gpt-3.5-turbo-0613',\n",
       " 'tts-1',\n",
       " 'dall-e-3',\n",
       " 'gpt-3.5-turbo-1106',\n",
       " 'babbage-002',\n",
       " 'gpt-4-0125-preview',\n",
       " 'gpt-4-turbo-preview',\n",
       " 'tts-1-1106',\n",
       " 'text-embedding-3-large',\n",
       " 'gpt-4-turbo-2024-04-09',\n",
       " 'gpt-4-vision-preview',\n",
       " 'text-embedding-3-small',\n",
       " 'gpt-4',\n",
       " 'text-embedding-ada-002',\n",
       " 'gpt-4-1106-vision-preview',\n",
       " 'gpt-4-1106-preview',\n",
       " 'gpt-4-0613',\n",
       " 'gpt-4-turbo']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from oa.base import list_engine_ids\n",
    "\n",
    "list_engine_ids()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oa import prompt_function, chat\n",
    "from functools import partial\n",
    "\n",
    "smarter_chat = partial(chat, model='gpt-4')\n",
    "smarter_prompt_function = partial(prompt_function, prompt_func=smarter_chat)\n",
    "# and now let's make a smarter prompt_template_improver\n",
    "# Since prompt_template_improver was already made with the default chat model,\n",
    "# we need to go back to the template, and make a new function with the new model\n",
    "smarter_prompt_template_improver = smarter_prompt_function(\n",
    "    ask.ai.prompt_template_improver.template_original\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative 1:\n",
      "For our language mastery exercise today, you are to translate the following phrases into {language:Japanese}. You will be utilizing these key phrases: {vocabulary_words}. Provide an index of {number_of_sentences:3} notions to translate and follow it with a SOLUTIONS segment where you catalog the accurate translations.\n",
      "\n",
      "Alternative 2:\n",
      "You are recognized for your proficiency in languages. The task here requires you to translate the subsequent sentences into {language:Japanese}, with a focus on these keywords: {vocabulary_words}. Try to construct and translate {number_of_sentences:3} original lines, followed by an ANSWERS segment displaying the correct translations.\n",
      "\n",
      "ADDITIONAL EXPLANATIONS:\n",
      "\n",
      "Alternative 1 slightly modifies the tone and language of the original template. In this alternative, the wording is a bit more formal. 'mastery exercise' is used instead of 'learning', which might help the AI take a more scholarly approach to the task. Also, by renaming the 'ANSWERS' to 'SOLUTIONS', it can make the AI generate answers in a more solution-providing way. These slight tweaks are done keeping the specific goal in mind that we want the AI to stick to the vocabulary words as closely as possible.\n",
      "\n",
      "Alternative 2 basically keeps the original structure of the prompt but enhances it by adding expressions such as 'recognized for your proficiency' and 'construct and translate original lines'. These add-ins are used to inspire the AI to stay more focused on utilizing the specified vocabulary words.\n",
      "\n",
      "PROMPT ENGINEERING TIPS:\n",
      "\n",
      "1. Always keep the end task in mind. The alterations in the template should be driven by what you want out of the task. In this case, to keep the focus on the vocabulary words. \n",
      "\n",
      "2. The tone of the prompt can significantly affect the output. If you want an output that is more formal or professional, consider using language that sounds more academic or professional.\n",
      "\n",
      "3. Consider the way you frame your instructions. Providing clear, specific instructions can help produce a response that more closely matches what you're looking for. \n",
      "\n",
      "4. Don't be afraid to experiment with your prompt. The slight alterations may cause the AI to approach the task in a way that you hadn't thought of.\n",
      "  \n",
      "5. Lastly, prompt engineering is more art than science. It requires understanding how the AI generates responses and using this knowledge to craft an effective prompt. Keep practicing, and you'll get better at it!\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "You are a language learning expert. Translate the following sentences into {language:Japanese} \n",
    "using the vocabulary words: {vocabulary_words}. \n",
    "Give me a list of {number_of_sentences:3} to translate followed with an ANSWERS section where \n",
    "you'll list the actual translations.\n",
    "\"\"\"\n",
    "alternative_template_3 = smarter_prompt_template_improver(\n",
    "    template,\n",
    "    specific_goals='To stay more focused on the vocabulary words, departing from them as little as possible', \n",
    "    number_of_alternatives=2, \n",
    "    include_additional_explanations=True, \n",
    "    prompt_engineering_tips=True\n",
    ")\n",
    "print(alternative_template_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oa.util import OPENAI_API_KEY_ENV_NAME, DFLT_TEMPLATES_SOURCE_ENV_NAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asdfasdf'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str.strip('asdfasdf ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"tuple\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_getter\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(config_getter\u001b[38;5;241m.\u001b[39msources[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mrootdir)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moa\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chat\n",
      "File \u001b[0;32m~/Dropbox/py/proj/t/oa/oa/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Python interface to OpenAi functionality\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m openai, grazed, djoin, app_data_dir\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chat, complete, dalle, api, embeddings\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai_specs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m raw\n",
      "File \u001b[0;32m~/Dropbox/py/proj/t/oa/oa/util.py:122\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_api_key_from_config\u001b[39m():\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_config(\n\u001b[1;32m    102\u001b[0m         OPENAI_API_KEY_ENV_NAME,\n\u001b[1;32m    103\u001b[0m         sources\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m         egress\u001b[38;5;241m=\u001b[39mkv_strip_value,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[0;32m--> 122\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[43mget_api_key_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmk_client\u001b[39m(api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclient_kwargs):\n\u001b[1;32m    127\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m api_key \u001b[38;5;129;01mor\u001b[39;00m get_api_key_from_config()\n",
      "File \u001b[0;32m~/Dropbox/py/proj/t/oa/oa/util.py:101\u001b[0m, in \u001b[0;36mget_api_key_from_config\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_api_key_from_config\u001b[39m():\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mOPENAI_API_KEY_ENV_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Try to find it in oa config\u001b[39;49;00m\n\u001b[1;32m    105\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfigs_local_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Try to find it in os.environ (environmental variables)\u001b[39;49;00m\n\u001b[1;32m    107\u001b[0m \u001b[43m            \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# If not, ask the user to input it\u001b[39;49;00m\n\u001b[1;32m    109\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mask_user_for_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPlease set your OpenAI API key and press enter to continue. \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m    111\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIf you don\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt have one, you can get one at \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    112\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://platform.openai.com/account/api-keys. \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmask_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmasking_toggle_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m                \u001b[49m\u001b[43megress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigs_local_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43megress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_strip_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dropbox/py/proj/i/config2py/config2py/base.py:218\u001b[0m, in \u001b[0;36mget_config\u001b[0;34m(key, sources, default, egress, val_is_valid, config_not_found_exceptions)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_config_\n\u001b[1;32m    217\u001b[0m chain_map \u001b[38;5;241m=\u001b[39m sources_chainmap(sources, val_is_valid, config_not_found_exceptions)\n\u001b[0;32m--> 218\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43mchain_map\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_not_found\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m config_not_found:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m default \u001b[38;5;129;01mis\u001b[39;00m no_default:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/collections/__init__.py:989\u001b[0m, in \u001b[0;36mChainMap.get\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m \u001b[38;5;28;01melse\u001b[39;00m default\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/collections/__init__.py:1001\u001b[0m, in \u001b[0;36mChainMap.__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__contains__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m-> 1001\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/collections/__init__.py:1001\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__contains__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m-> 1001\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaps)\n",
      "File \u001b[0;32m~/Dropbox/py/proj/i/dol/dol/base.py:635\u001b[0m, in \u001b[0;36mStore.__contains__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__contains__\u001b[39m(\u001b[38;5;28mself\u001b[39m, k) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 635\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id_of_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\n",
      "File \u001b[0;32m~/Dropbox/py/proj/i/dol/dol/paths.py:736\u001b[0m, in \u001b[0;36mPrefixRelativizationMixin._id_of_key\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_id_of_key\u001b[39m(\u001b[38;5;28mself\u001b[39m, k):\n\u001b[0;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prefix_attr_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"tuple\") to str"
     ]
    }
   ],
   "source": [
    "from oa.util import config_getter\n",
    "\n",
    "print(config_getter.sources[0].rootdir)\n",
    "\n",
    "from oa import chat\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'oa' from '/Users/thorwhalen/Dropbox/py/proj/t/oa/oa/__init__.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import oa\n",
    "oa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oa.util import config_getter\n",
    "\n",
    "config_getter('OPENAI_API_KEY_ENV_NAME', default='OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FuncBasedGettableContainer(getter=<functools._lru_cache_wrapper object at 0x10a0cdbc0>, val_is_valid=<function always_true at 0x10a090310>, config_not_found_exceptions=(<class 'Exception'>,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPENAI_API_KEY_ENV_NAME = 'OPENAI_API_KEY'\n",
    "DFLT_TEMPLATES_SOURCE_ENV_NAME = 'OA_DFLT_TEMPLATES_SOURCE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['test123']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "TypeError('write() argument must be str, not None')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Dropbox/py/proj/i/dol/dol/filesys.py:144\u001b[0m, in \u001b[0;36mvalidate_key_and_raise_key_error_on_exception.<locals>.wrapped_method\u001b[0;34m(self, k, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Dropbox/py/proj/i/dol/dol/filesys.py:374\u001b[0m, in \u001b[0;36mFileBytesPersister.__setitem__\u001b[0;34m(self, k, v)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(k, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_open_kwargs) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m--> 374\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not None",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest123\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dropbox/py/proj/i/config2py/config2py/base.py:388\u001b[0m, in \u001b[0;36mask_user_for_key\u001b[0;34m(key, prompt_template, save_to, user_asker, egress)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(save_to, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setitem__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    387\u001b[0m         save_to_func \u001b[38;5;241m=\u001b[39m save_to\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setitem__\u001b[39m\n\u001b[0;32m--> 388\u001b[0m     \u001b[43msave_to_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val\n",
      "File \u001b[0;32m~/Dropbox/py/proj/i/dol/dol/base.py:670\u001b[0m, in \u001b[0;36mStore.__setitem__\u001b[0;34m(self, k, v)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, k: Key, v: Val):\n\u001b[0;32m--> 670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id_of_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_of_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dropbox/py/proj/i/dol/dol/filesys.py:146\u001b[0m, in \u001b[0;36mvalidate_key_and_raise_key_error_on_exception.<locals>.wrapped_method\u001b[0;34m(self, k, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, k, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(e)\n",
      "\u001b[0;31mKeyError\u001b[0m: TypeError('write() argument must be str, not None')"
     ]
    }
   ],
   "source": [
    "s.getter('test123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "class NonIterable:\n",
    "    def __init__(self):\n",
    "        self.__iter__ = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index >= 0 and index < 10:\n",
    "            return index\n",
    "        else:\n",
    "            raise IndexError('Index out of range')\n",
    "\n",
    "obj = NonIterable()\n",
    "print(isinstance(obj, Iterable))  # This will return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "class NonIterable:\n",
    "    def __init__(self):\n",
    "        self.__iter__ = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index >= 0 and index < 10:\n",
    "            return index\n",
    "        else:\n",
    "            raise IndexError('Index out of range')\n",
    "\n",
    "obj = NonIterable()\n",
    "print(isinstance(obj, Iterable))  # This will return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your own templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I mean, really we've already gone through the motions now, perhaps unknowlingly.\n",
    "\n",
    "We took a pre existing ai-based function as our point of departure, but have seen how it itself was \n",
    "made from a prompt template string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Invalid base64-encoded string: number of data characters (61) cannot be 1 more than a multiple of 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbase64\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m b64encode, b64decode\n\u001b[0;32m----> 3\u001b[0m \u001b[43mb64decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbase64,aW1wb3J0IHJlcXVlc3RzCgojIEZvbmN0aW9uIHBvdXIgZWZmZWN0dWV\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/base64.py:87\u001b[0m, in \u001b[0;36mb64decode\u001b[0;34m(s, altchars, validate)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39mfullmatch(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[A-Za-z0-9+/]*=\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m0,2}\u001b[39m\u001b[38;5;124m'\u001b[39m, s):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m binascii\u001b[38;5;241m.\u001b[39mError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNon-base64 digit found\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinascii\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ma2b_base64\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mError\u001b[0m: Invalid base64-encoded string: number of data characters (61) cannot be 1 more than a multiple of 4"
     ]
    }
   ],
   "source": [
    "from base64 import b64encode, b64decode\n",
    "\n",
    "b64decode(\"base64,aW1wb3J0IHJlcXVlc3RzCgojIEZvbmN0aW9uIHBvdXIgZWZmZWN0dWV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"data:text/x-python;name=update_all_prompt.py;base64,aW1wb3J0IHJlcXVlc3RzCgojIEZvbmN0aW9uIHBvdXIgZWZmZWN0dWV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python',\n",
       " 'name=update_all_prompt.py',\n",
       " 'base64,aW1wb3J0IHJlcXVlc3RzCgojIEZvbmN0aW9uIHBvdXIgZWZmZWN0dWV']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decode this base64 string:\n",
    "\n",
    "t = \"python;name=update_all_prompt.py;base64,aW1wb3J0IHJlcXVlc3RzCgojIEZvbmN0aW9uIHBvdXIgZWZmZWN0dWV\"\n",
    "\n",
    "tt = t.split(\";\")\n",
    "\n",
    "# get the contents of this file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import requests\n",
      "\n",
      "# Fonction pour effectue\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def extract_string_from_data_url(data_url):\n",
    "    \"\"\"Extract a string from a data URL.\"\"\"\n",
    "    import base64\n",
    "\n",
    "    # Split the URL at the first comma to separate the metadata from the base64 content\n",
    "    metadata, encoded = data_url.split(',', 1)\n",
    "\n",
    "    # Ensure the base64 string is a multiple of 4 in length by padding with '='\n",
    "    padding = 4 - len(encoded) % 4\n",
    "    if padding and padding != 4:\n",
    "        encoded += '=' * padding\n",
    "\n",
    "    # Decode the base64 string\n",
    "    original_string = base64.b64decode(encoded).decode('utf-8')\n",
    "\n",
    "    return original_string\n",
    "\n",
    "\n",
    "data_url = \"data:text/x-python;name=update_all_prompt.py;base64,aW1wb3J0IHJlcXVlc3RzCgojIEZvbmN0aW9uIHBvdXIgZWZmZWN0dWV\"\n",
    "\n",
    "try:\n",
    "    original_content = extract_string_from_data_url(data_url)\n",
    "    print(original_content)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CURRICULUM VITAE\\nThor Whalen CURRENT POSITION: Director of Machine Learning\\nDEGREE: Mathematics Ph.D. & Computer Science Masters.\\nLife: Born in the U.S., raised in France (mostly), Italy and Germany. US citizen.\\nWork: Consultant & Analyst: Data Science, Mathematics, Statistical Modeling, Optimization, Computer Science Natural Languages: English, French (bilingual), Italian (working knowledge), German (conversational) Computing Languages: Python Expert. Historical: C, Matlab, R, Java, VBA. Prehistorical: Basic, Pascal, Lisp Email: thor.c.whalen@gmail.com Phone: +1-929-422-1134\\nWORK\\nI have worked primarily as an independent machine learning consultant and trainer since year 2000. My work required a cross-functional approach to problem solving in a variety of sectors. It usually started with formalizing what the C-levels wanted, defining and measuring objectives, developing models, and finally working with existing dev teams to get the solutions integrated.\\nI co-founded OtoSense, a sound recognition company. We sold it to Analog Devices in 2018 and I have been working with them since then, first as a Director of Machine Learning, focused on open-source tools to facilitate collaboration for the development of end-to-end frameworks and platforms for signal ML.\\n  Analog Devices\\n(Semiconductors)\\nOtoSense\\n(Sound Recognition)\\nTagCommander\\n(Tag Management System)\\nExpedia\\n(Hotel Booking)\\n2018- Director of Machine Learning (Analog Devices bought OtoSense) present - Managing R&D in IoT data machine learning and platforms\\n- Develop tools to accelerate end-to-end ML POC development\\n2016- CTO and co-founder of startup\\n2018 - Data Science for sound recognition AI systems\\n- Managed backend and frontend projects for sound recognition tools\\n2014- Senior Data Scientist\\n2016 - Sales Trajectory Analysis - Multi-channel Attribution\\n2011- 2014\\n- Search Engine Marketing Optimization\\n- Supply and Demand granularization, alignment, and pricing - Semantic Analysis and Consumer Behavior\\nFrom 2001-2011 I worked as an independent consultant. Below is a list of companies I worked for, and a short work description. The time periods of the projects—neither contiguous nor separate—will be omitted for readability.\\nSanoma\\n(Media)\\nEasyvoyage\\n(Fare comparator)\\nDotdotdot\\n(Mobile Reader App)\\nFirst Affiliation\\n(Internet Marketing)\\nScentric\\n(Data Management)\\n- Examined online marketing process and strategies, integration of data science teams - Presented algorithms to improve search marketing\\n- Airfare forecasting - Data Analysis\\n- Natural language processing - Document fingerprinting\\n- Designed and developed automatic targeting and campaign optimization system for affiliation and direct mail marketing\\n- Time series analysis and forecasting of various marketing variables\\n- Search engine marketing: Forecasting, risk management and bid optimization\\n- Research and development in data management and information retrieval. - Developed general duplicate detection system -- wrote and filed patent.\\n- Automatic document classification\\niViVity\\n(Storage Management and Networking)\\nKM Consulting\\n(Knowledge Management)\\nMetron\\n(Scientific Consulting)\\nIKON (now Ricoh) (Office Solutions)\\nNursing Home Quality\\n(QIS experts)\\n- Improved existing methods for RAID systems and CRC calculations\\n- Wrote patent (US patent #6,823,425) on novel erasure codes for RAID systems - Analyzed hash functions’ effectiveness and (circuit design) optimality\\n- Conducted workshops on diverse mathematical techniques\\n- Conducted workshops on data mining, forecasting, artificial intelligence, expertise systemization and knowledge extraction.\\n- Worked on expressing knowledge management problems in mathematical form\\n- Developed theory and software tool for distributed inference in Bayesian networks - Researched and tested Monte Carlo methods for multiple target tracking\\n- Modeling incentive analysis and alignment\\n- Wrote software tool for compensation plan analysis\\n- Developed an approach to assess precision and optimize risk and cost during QIS (quality indicator score) facility quality assessment. Developed simulations.\\nOther miscellaneous projects include\\nIdentification information of mouse movements and keystroke patterns Betting (number combination) choices of national lottery\\nEmergence & spread of new words and expression in the blogosphere Addiction patterns and dynamics\\nDEGREES / EDUCATION\\nOnline poker betting patterns Auction dynamics\\nSocial network structure of blogs Music information retrieval\\n Ph.D. in Mathematics\\nM.S. in Computer Science\\nLicence de Mathématiques (M.S. in Math) D.E.U.G. A MPM (B.S. in Math/Physics) Graduate Studies\\nClassical and Jazz musical studies\\nEmory University 2003 Emory University 2003 Université de Nice Sophia Antipolis, Nice, France 1996 Université de Nice Sophia Antipolis, Nice, France 1994 Technische Universität Berlin, Germany 1997-1998 Conservatoire National de Région de Nice, France 1985-1995\\nTEACHING EXPERIENCE\\nTaught in several Universities (namely, Illinois State University, Emory University, Johns Hopkins Center for Talented Youth) across the U.S.A & various workshops in various subjects relevant to the client. Subjects include:\\n Marketing mathematics Probability and Statistics Theory of Computing\\nMathematics for Computer Science Advanced data analysis\\nData Science in Python\\nPATENTS & ACADEMIC ARTICLES\\nExploiting uncertainty\\nOptimizing in complex settings Data representation and indexation\\n Below is a non-exhaustive list of publications.\\n1. Syntactic system for sound recognition, w/ Christian, US Patent #US20180268844A1\\n2. Sound-recognition system based on a sound language and associated annotations, w/ Christian, US Patent #US20180254054A1\\n3. System and method for implementing advanced RAID using a set of unique matrices as Coefficients, w/ Gosh, Jain, US Patent #6,823,425\\n(assignee: iVivity, Inc.)\\n4. Intelligent General Duplicate Management System w/ Kurande. US Patent 2007/0050423 (assignee: Scentric, Inc)\\n5. Measuring Discontinuity in Binary Longitudinal Data, w/ Miriam Boeri: Sociological methods & research. 43(2) (2014)\\n6. On H-immersions, w/ Ferrara, Tansey, Gould: Graph Theory 57(3) (2008)\\n7. Subdivision Extendibility, w/ Gould: Graphs Combin. 23(2) (2007)\\n8. Distance between two k-sets and path-system extendibility, w/ Gould: Ars Combinatoria 79 (2006\\n9. On H-linked Graphs: Unifying connectivity, w/ Ferrara, Tansey, Gould: Graphs Combin. 22(2) (2006)\\n10. Edge-disjoint Hamiltonian cycles in bipartite graphs, w/ Ferrara, Tansey, Gould, Discrete Mathematics 309(12) (2009)\\n11. Pan-k-linkage in dense graphs, w/ Gould, Powell, Wagner: Discrete Mathematics 309(10) (2009)\\n12. Irregularity Strength of Digraphs, w/ Ferrara, Gilbert, Jacobson: Discrete Mathematics 309(19) (2009)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = {\n",
    "  \"files\": [],\n",
    "  \"file\": \"data:text/plain;name=thor_whalen_cv.txt;base64,CURRICULUM VITAE
Thor Whalen CURRENT POSITION: Director of Machine Learning
DEGREE: Mathematics Ph.D. & Computer Science Masters.
Life: Born in the U.S., raised in France (mostly), Italy and Germany. US citizen.
Work: Consultant & Analyst: Data Science, Mathematics, Statistical Modeling, Optimization, Computer Science Natural Languages: English, French (bilingual), Italian (working knowledge), German (conversational) Computing Languages: Python Expert. Historical: C, Matlab, R, Java, VBA. Prehistorical: Basic, Pascal, Lisp Email: thor.c.whalen@gmail.com Phone: +1-929-422-1134
WORK
I have worked primarily as an independent machine learning consultant and trainer since year 2000. My work required a cross-functional approach to problem solving in a variety of sectors. It usually started with formalizing what the C-levels wanted, defining and measuring objectives, developing models, and finally working with existing dev teams to get the solutions integrated.
I co-founded OtoSense, a sound recognition company. We sold it to Analog Devices in 2018 and I have been working with them since then, first as a Director of Machine Learning, focused on open-source tools to facilitate collaboration for the development of end-to-end frameworks and platforms for signal ML.
  Analog Devices
(Semiconductors)
OtoSense
(Sound Recognition)
TagCommander
(Tag Management System)
Expedia
(Hotel Booking)
2018- Director of Machine Learning (Analog Devices bought OtoSense) present - Managing R&D in IoT data machine learning and platforms
- Develop tools to accelerate end-to-end ML POC development
2016- CTO and co-founder of startup
2018 - Data Science for sound recognition AI systems
- Managed backend and frontend projects for sound recognition tools
2014- Senior Data Scientist
2016 - Sales Trajectory Analysis - Multi-channel Attribution
2011- 2014
- Search Engine Marketing Optimization
- Supply and Demand granularization, alignment, and pricing - Semantic Analysis and Consumer Behavior
From 2001-2011 I worked as an independent consultant. Below is a list of companies I worked for, and a short work description. The time periods of the projects—neither contiguous nor separate—will be omitted for readability.
Sanoma
(Media)
Easyvoyage
(Fare comparator)
Dotdotdot
(Mobile Reader App)
First Affiliation
(Internet Marketing)
Scentric
(Data Management)
- Examined online marketing process and strategies, integration of data science teams - Presented algorithms to improve search marketing
- Airfare forecasting - Data Analysis
- Natural language processing - Document fingerprinting
- Designed and developed automatic targeting and campaign optimization system for affiliation and direct mail marketing
- Time series analysis and forecasting of various marketing variables
- Search engine marketing: Forecasting, risk management and bid optimization
- Research and development in data management and information retrieval. - Developed general duplicate detection system -- wrote and filed patent.
- Automatic document classification
iViVity
(Storage Management and Networking)
KM Consulting
(Knowledge Management)
Metron
(Scientific Consulting)
IKON (now Ricoh) (Office Solutions)
Nursing Home Quality
(QIS experts)
- Improved existing methods for RAID systems and CRC calculations
- Wrote patent (US patent #6,823,425) on novel erasure codes for RAID systems - Analyzed hash functions’ effectiveness and (circuit design) optimality
- Conducted workshops on diverse mathematical techniques
- Conducted workshops on data mining, forecasting, artificial intelligence, expertise systemization and knowledge extraction.
- Worked on expressing knowledge management problems in mathematical form
- Developed theory and software tool for distributed inference in Bayesian networks - Researched and tested Monte Carlo methods for multiple target tracking
- Modeling incentive analysis and alignment
- Wrote software tool for compensation plan analysis
- Developed an approach to assess precision and optimize risk and cost during QIS (quality indicator score) facility quality assessment. Developed simulations.
Other miscellaneous projects include
Identification information of mouse movements and keystroke patterns Betting (number combination) choices of national lottery
Emergence & spread of new words and expression in the blogosphere Addiction patterns and dynamics
DEGREES / EDUCATION
Online poker betting patterns Auction dynamics
Social network structure of blogs Music information retrieval
 Ph.D. in Mathematics
M.S. in Computer Science
Licence de Mathématiques (M.S. in Math) D.E.U.G. A MPM (B.S. in Math/Physics) Graduate Studies
Classical and Jazz musical studies
Emory University 2003 Emory University 2003 Université de Nice Sophia Antipolis, Nice, France 1996 Université de Nice Sophia Antipolis, Nice, France 1994 Technische Universität Berlin, Germany 1997-1998 Conservatoire National de Région de Nice, France 1985-1995
TEACHING EXPERIENCE
Taught in several Universities (namely, Illinois State University, Emory University, Johns Hopkins Center for Talented Youth) across the U.S.A & various workshops in various subjects relevant to the client. Subjects include:
 Marketing mathematics Probability and Statistics Theory of Computing
Mathematics for Computer Science Advanced data analysis
Data Science in Python
PATENTS & ACADEMIC ARTICLES
Exploiting uncertainty
Optimizing in complex settings Data representation and indexation
 Below is a non-exhaustive list of publications.
1. Syntactic system for sound recognition, w/ Christian, US Patent #US20180268844A1
2. Sound-recognition system based on a sound language and associated annotations, w/ Christian, US Patent #US20180254054A1
3. System and method for implementing advanced RAID using a set of unique matrices as Coefficients, w/ Gosh, Jain, US Patent #6,823,425
(assignee: iVivity, Inc.)
4. Intelligent General Duplicate Management System w/ Kurande. US Patent 2007/0050423 (assignee: Scentric, Inc)
5. Measuring Discontinuity in Binary Longitudinal Data, w/ Miriam Boeri: Sociological methods & research. 43(2) (2014)
6. On H-immersions, w/ Ferrara, Tansey, Gould: Graph Theory 57(3) (2008)
7. Subdivision Extendibility, w/ Gould: Graphs Combin. 23(2) (2007)
8. Distance between two k-sets and path-system extendibility, w/ Gould: Ars Combinatoria 79 (2006
9. On H-linked Graphs: Unifying connectivity, w/ Ferrara, Tansey, Gould: Graphs Combin. 22(2) (2006)
10. Edge-disjoint Hamiltonian cycles in bipartite graphs, w/ Ferrara, Tansey, Gould, Discrete Mathematics 309(12) (2009)
11. Pan-k-linkage in dense graphs, w/ Gould, Powell, Wagner: Discrete Mathematics 309(10) (2009)
12. Irregularity Strength of Digraphs, w/ Ferrara, Gilbert, Jacobson: Discrete Mathematics 309(19) (2009)\"\n",
    "}\n",
    "\n",
    "extract_string_from_data_url(t[\"file\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \"file\": \"data:text/plain;name=thor_whalen_cv.txt;base64,CURRICULUM VITAE
Thor Whalen CURRENT POSITION: Director of Machine Learning
DEGREE: Mathematics Ph.D. & Computer Science Masters.
Life: Born in the U.S., raised in France (mostly), Italy and Germany. US citizen.
Work: Consultant & Analyst: Data Science, Mathematics, Statistical Modeling, Optimization, Computer Science Natural Languages: English, French (bilingual), Italian (working knowledge), German (conversational) Computing Languages: Python Expert. Historical: C, Matlab, R, Java, VBA. Prehistorical: Basic, Pascal, Lisp Email: thor.c.whalen@gmail.com Phone: +1-929-422-1134
WORK
I have worked primarily as an independent machine learning consultant and trainer since year 2000. My work required a cross-functional approach to problem solving in a variety of sectors. It usually started with formalizing what the C-levels wanted, defining and measuring objectives, developing models, and finally working with existing dev teams to get the solutions integrated.
I co-founded OtoSense, a sound recognition company. We sold it to Analog Devices in 2018 and I have been working with them since then, first as a Director of Machine Learning, focused on open-source tools to facilitate collaboration for the development of end-to-end frameworks and platforms for signal ML.
  Analog Devices
(Semiconductors)
OtoSense
(Sound Recognition)
TagCommander
(Tag Management System)
Expedia
(Hotel Booking)
2018- Director of Machine Learning (Analog Devices bought OtoSense) present - Managing R&D in IoT data machine learning and platforms
- Develop tools to accelerate end-to-end ML POC development
2016- CTO and co-founder of startup
2018 - Data Science for sound recognition AI systems
- Managed backend and frontend projects for sound recognition tools
2014- Senior Data Scientist
2016 - Sales Trajectory Analysis - Multi-channel Attribution
2011- 2014
- Search Engine Marketing Optimization
- Supply and Demand granularization, alignment, and pricing - Semantic Analysis and Consumer Behavior
From 2001-2011 I worked as an independent consultant. Below is a list of companies I worked for, and a short work description. The time periods of the projects—neither contiguous nor separate—will be omitted for readability.
Sanoma
(Media)
Easyvoyage
(Fare comparator)
Dotdotdot
(Mobile Reader App)
First Affiliation
(Internet Marketing)
Scentric
(Data Management)
- Examined online marketing process and strategies, integration of data science teams - Presented algorithms to improve search marketing
- Airfare forecasting - Data Analysis
- Natural language processing - Document fingerprinting
- Designed and developed automatic targeting and campaign optimization system for affiliation and direct mail marketing
- Time series analysis and forecasting of various marketing variables
- Search engine marketing: Forecasting, risk management and bid optimization
- Research and development in data management and information retrieval. - Developed general duplicate detection system -- wrote and filed patent.
- Automatic document classification
iViVity
(Storage Management and Networking)
KM Consulting
(Knowledge Management)
Metron
(Scientific Consulting)
IKON (now Ricoh) (Office Solutions)
Nursing Home Quality
(QIS experts)
- Improved existing methods for RAID systems and CRC calculations
- Wrote patent (US patent #6,823,425) on novel erasure codes for RAID systems - Analyzed hash functions’ effectiveness and (circuit design) optimality
- Conducted workshops on diverse mathematical techniques
- Conducted workshops on data mining, forecasting, artificial intelligence, expertise systemization and knowledge extraction.
- Worked on expressing knowledge management problems in mathematical form
- Developed theory and software tool for distributed inference in Bayesian networks - Researched and tested Monte Carlo methods for multiple target tracking
- Modeling incentive analysis and alignment
- Wrote software tool for compensation plan analysis
- Developed an approach to assess precision and optimize risk and cost during QIS (quality indicator score) facility quality assessment. Developed simulations.
Other miscellaneous projects include
Identification information of mouse movements and keystroke patterns Betting (number combination) choices of national lottery
Emergence & spread of new words and expression in the blogosphere Addiction patterns and dynamics
DEGREES / EDUCATION
Online poker betting patterns Auction dynamics
Social network structure of blogs Music information retrieval
 Ph.D. in Mathematics
M.S. in Computer Science
Licence de Mathématiques (M.S. in Math) D.E.U.G. A MPM (B.S. in Math/Physics) Graduate Studies
Classical and Jazz musical studies
Emory University 2003 Emory University 2003 Université de Nice Sophia Antipolis, Nice, France 1996 Université de Nice Sophia Antipolis, Nice, France 1994 Technische Universität Berlin, Germany 1997-1998 Conservatoire National de Région de Nice, France 1985-1995
TEACHING EXPERIENCE
Taught in several Universities (namely, Illinois State University, Emory University, Johns Hopkins Center for Talented Youth) across the U.S.A & various workshops in various subjects relevant to the client. Subjects include:
 Marketing mathematics Probability and Statistics Theory of Computing
Mathematics for Computer Science Advanced data analysis
Data Science in Python
PATENTS & ACADEMIC ARTICLES
Exploiting uncertainty
Optimizing in complex settings Data representation and indexation
 Below is a non-exhaustive list of publications.
1. Syntactic system for sound recognition, w/ Christian, US Patent #US20180268844A1
2. Sound-recognition system based on a sound language and associated annotations, w/ Christian, US Patent #US20180254054A1
3. System and method for implementing advanced RAID using a set of unique matrices as Coefficients, w/ Gosh, Jain, US Patent #6,823,425
(assignee: iVivity, Inc.)
4. Intelligent General Duplicate Management System w/ Kurande. US Patent 2007/0050423 (assignee: Scentric, Inc)
5. Measuring Discontinuity in Binary Longitudinal Data, w/ Miriam Boeri: Sociological methods & research. 43(2) (2014)
6. On H-immersions, w/ Ferrara, Tansey, Gould: Graph Theory 57(3) (2008)
7. Subdivision Extendibility, w/ Gould: Graphs Combin. 23(2) (2007)
8. Distance between two k-sets and path-system extendibility, w/ Gould: Ars Combinatoria 79 (2006
9. On H-linked Graphs: Unifying connectivity, w/ Ferrara, Tansey, Gould: Graphs Combin. 22(2) (2006)
10. Edge-disjoint Hamiltonian cycles in bipartite graphs, w/ Ferrara, Tansey, Gould, Discrete Mathematics 309(12) (2009)
11. Pan-k-linkage in dense graphs, w/ Gould, Powell, Wagner: Discrete Mathematics 309(10) (2009)
12. Irregularity Strength of Digraphs, w/ Ferrara, Gilbert, Jacobson: Discrete Mathematics 309(19) (2009)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
